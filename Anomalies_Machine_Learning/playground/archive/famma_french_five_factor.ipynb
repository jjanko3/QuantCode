{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries for analysis\n",
    "#pandas for dataframes\n",
    "import pandas as pd\n",
    "#datetime for converting numerics to datetime format\n",
    "import datetime as dt\n",
    "#yahoo finance dividend adjusted closes for prototyping\n",
    "import yfinance as yf\n",
    "#statsmodels for ols regressions\n",
    "import statsmodels.api as sm\n",
    "#convert dataframes to numpy format because sklearn does not take dataframes well\n",
    "import numpy as np\n",
    "from finance_byu.fama_macbeth import fama_macbeth, fama_macbeth_parallel, fm_summary, fama_macbeth_numba\n",
    "\n",
    "\n",
    "#this is the list of classifiers from sklearn that are available for analysis. \"kitchen sink\" approach\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a base class which we use put our parameters. All the other classes inherit from this\n",
    "class BacktestParameters:\n",
    "    \n",
    "    def __init__(self, stk_symbols, start, end, lookback_alpha, lev):\n",
    "        #the stock symbols\n",
    "        self.stk_symbols = stk_symbols\n",
    "        #start of the data series\n",
    "        self.start = start\n",
    "        #end of the data series\n",
    "        self.end = end\n",
    "        #index security\n",
    "        #the lookback period for calculating alpha and idiosyncratic volatility\n",
    "        self.lookback = lookback_alpha\n",
    "        #leverage to apply to the strategy\n",
    "        self.lev = lev\n",
    "\n",
    "#class for pulling the yahoo finance data and cleaning so we have monthly data\n",
    "class Data(BacktestParameters):\n",
    "    \n",
    "    def __init__(self, bp):\n",
    "        #inherit from the base class\n",
    "        self.stk_symbols = bp.stk_symbols\n",
    "        self.start = bp.start\n",
    "        self.end = bp.end\n",
    "        self.lookback = bp.lookback\n",
    "        \n",
    "    #method for get getting the adjusted closes from yahoo\n",
    "    def get_data(self):\n",
    "        close = pd.DataFrame()\n",
    "\n",
    "        for i in self.stk_symbols:\n",
    "\n",
    "            df = yf.download(i, start=self.start, end=self.end, progress=False)\n",
    "            df = pd.DataFrame(df['Adj Close'])\n",
    "            df.columns = [i]\n",
    "            if close.empty:\n",
    "                close = df.copy()\n",
    "            else:\n",
    "                close = pd.concat([close, df], axis = 1)\n",
    "\n",
    "        #get the daily returns\n",
    "        returns = close.pct_change()[1:]\n",
    "\n",
    "        print(returns.head())\n",
    "        \n",
    "        return returns\n",
    "    \n",
    "    #converts the daily returns to a geometric return for the month\n",
    "    def convert_monthly(self, returns):\n",
    "        returns = returns.resample('M').agg(lambda x: (x + 1).prod(skipna = True) - 1)\n",
    "        \n",
    "        #the geometric returns convert null values at the beginning of the time series to zeros.\n",
    "        #this converts the data back to null values so we dont allocate to data that does not exist \n",
    "        for i in returns.columns:\n",
    "            found = False\n",
    "            for date, row in returns.loc[:,i].iteritems():\n",
    "                if row == 0.0 and ~found:\n",
    "                    returns.loc[date, i] = np.nan\n",
    "                else:\n",
    "                    found = True\n",
    "        print(returns)\n",
    "        return returns\n",
    "    \n",
    "    \n",
    "    #this method takes a dataframe and converts to a binary output based off the center variable\n",
    "    def get_binary(self, df_input, center = 0.0):\n",
    "        \n",
    "        binary_alpha = df_input.astype(float)\n",
    "        #greater than the center var is a 1\n",
    "        binary_alpha[binary_alpha >= center] = 1.0\n",
    "        #less than the center var is a 0.0\n",
    "        binary_alpha[binary_alpha < center] = 0.0\n",
    "        \n",
    "        return binary_alpha\n",
    "        \n",
    "#class for the backtesting of our classification\n",
    "class Backtest():\n",
    "    #instantiate with the backtest parameters with the returns data\n",
    "    def __init__(self, bp, returns, mode):\n",
    "        #the stock symbols\n",
    "        self.stk_symbols = bp.stk_symbols\n",
    "        #start of the data series\n",
    "        self.start = bp.start\n",
    "        #end of the data series\n",
    "        self.end = bp.end\n",
    "        #index security\n",
    "        #the lookback period for calculating alpha\n",
    "        self.lookback = bp.lookback\n",
    "        self.returns = returns\n",
    "        self.mode = mode\n",
    "        \n",
    "        \n",
    "    def check_new_factor(self, backtest, factor_model, index_symbol):\n",
    "        \n",
    "        new_factor = pd.DataFrame(backtest.mean(axis = 1))\n",
    "        new_factor.columns = ['portfolio']\n",
    "\n",
    "        Y = factor_model.loc[new_factor.index, index_symbol]\n",
    "        Y = pd.DataFrame(Y)\n",
    "        X = factor_model.loc[new_factor.index]\n",
    "        X = pd.concat([new_factor, X], axis = 1)\n",
    "        X['intercept'] = 1.0\n",
    "        X = X.shift(1).dropna(axis = 0)\n",
    "        Y = Y.iloc[1:]\n",
    "        model = sm.OLS(Y,X, missing = 'drop')\n",
    "        results = model.fit()\n",
    "        print(results.summary())  \n",
    "        betas = results.params\n",
    "\n",
    "        #2nd step. regress all asset returns for a fixed time period against the estimated betas to determine the risk premium for each factor.\n",
    "\n",
    "        prems = {}\n",
    "        for count, row in X.iterrows():\n",
    "            y = Y.loc[count]\n",
    "            y = pd.DataFrame(y).T\n",
    "            x = pd.DataFrame(row).T\n",
    "            model = sm.OLS(y,x, missing = 'drop')\n",
    "            results = model.fit()\n",
    "            prems[count] = results.params\n",
    "\n",
    "        print(\"Factor Loadings\")\n",
    "        prems = pd.DataFrame(prems).T\n",
    "        print(prems.head(20))\n",
    "        expected_prems = prems.mean()\n",
    "        t_stats = expected_prems / (prems.std()/ np.sqrt(len(prems.index)))\n",
    "        print(\"expected premiums for each risk factor\")\n",
    "        print(expected_prems)\n",
    "        print(\"t-stats for each risk factor\")\n",
    "        print(t_stats)\n",
    "  \n",
    "            \n",
    "    \"\"\"\n",
    "    this method gets the equal weight portfolio of our strategy and compares to the factor model of choice. \n",
    "    Takes the backtest dataframe which is the actual returns of the strategy.\n",
    "    \"\"\"\n",
    "    \n",
    "    def factor_results(self, backtest, factor_model):\n",
    "        \n",
    "        port= pd.DataFrame(backtest.mean(axis = 1))\n",
    "        port.columns = ['portfolio']\n",
    "\n",
    "        #1st step. run the regression of factors on the portfolio\n",
    "        Y = pd.DataFrame(port).shift(-1)\n",
    "        X = factor_model.loc[port.index]\n",
    "        X['intercept'] = 1.0\n",
    "        model = sm.OLS(Y,X,missing = 'drop')\n",
    "        results = model.fit()\n",
    "        print(results.summary())  \n",
    "        betas = results.params\n",
    "\n",
    "        #2nd step. regress all asset returns for a fixed time period against the estimated betas to determine the risk premium for each factor.\n",
    "\n",
    "        prems = {}\n",
    "        for count, row in X.iterrows():\n",
    "            try:\n",
    "                y = Y.loc[count,:]\n",
    "                y = pd.DataFrame(y).T\n",
    "                x = pd.DataFrame(row).T\n",
    "                model = sm.OLS(y,x, missing = 'drop')\n",
    "                results = model.fit()\n",
    "                prems[count] = results.params\n",
    "            except:\n",
    "                #this is to deal nans in the y and x\n",
    "                pass\n",
    "\n",
    "        print(\"Factor Loadings\")\n",
    "        prems = pd.DataFrame(prems).T\n",
    "        print(prems.head(20))\n",
    "        expected_prems = prems.mean()\n",
    "        t_stats = expected_prems / (prems.std()/ np.sqrt(len(prems.index)))\n",
    "        print(\"expected premiums for each risk factor\")\n",
    "        print(expected_prems)\n",
    "        print(\"t-stats for each risk factor\")\n",
    "        print(t_stats)\n",
    "\n",
    " \n",
    "    \n",
    "    #this method is for actually running the backtest and getting the portfolios returns and allocations\n",
    "    def run_backtest(self, input_classifiers, lookback_backtest, inputs, outputs,  ensemble = 'no', trade_type = 'both'):\n",
    "        \n",
    "        \"\"\"\n",
    "        the input_classifiers is a string of which classifier to use. This can be an array for multiple classifiers\n",
    "        lookback_test is an integer for the time length to use for the feature set to use for the analysis\n",
    "        inputs is a dataframe of the feature set\n",
    "        output is a dataframe of the output variable to train our feature set on. This is returns across the assets\n",
    "        for analysis\n",
    "        ensemble is a yes or not string for whether to take an array of classifiers and a voting method to get \n",
    "        asset returns\n",
    "        trade_type: this determines if the portfolio is long only, short only, or both\n",
    "        \"\"\"\n",
    "        \n",
    "        #gets the lowercase sting of the ensemble input.\n",
    "        ensemble = ensemble.lower()\n",
    "        \n",
    "        #if we input multiple classifiers this converts the system to an ensemble output. You can only input one\n",
    "        #classifier at a time or an ensemble system\n",
    "        if ensemble == 'no' and len(input_classifiers) > 1:\n",
    "            print(\"For non emsemble systems the amount of input classifiers are restricted to one. The following backtest will be changed to a ensemble system\")\n",
    "            ensemble = 'yes'\n",
    "        \n",
    "        \n",
    "        #dictionary to convert the classifiers string inputs to actual sklearn classifiers\n",
    "        classifiers = {\"Nearest Neighbors\" : KNeighborsClassifier(3), \\\n",
    "                       \"Linear SVM\" : SVC(),\\\n",
    "                        \"RBF SVM\": SVC(gamma=2, C=1), \\\n",
    "                        \"Gaussian Process\" : GaussianProcessClassifier(1.0 * RBF(1.0)), \\\n",
    "                        \"Decision Tree\" : DecisionTreeClassifier(max_depth=5), \\\n",
    "                        \"Random Forest\" : RandomForestClassifier(max_depth=3, n_estimators=2, max_features=1, random_state=1), \\\n",
    "                        \"Neural Net\": MLPClassifier(solver='adam', learning_rate = 'adaptive', alpha=1e-3, hidden_layer_sizes=(5),max_iter= 10000, random_state=1), \\\n",
    "                        \"AdaBoost\": AdaBoostClassifier(), \\\n",
    "                        \"Naive Bayes\": GaussianNB(), \\\n",
    "                        \"QDA\": QuadraticDiscriminantAnalysis()}\n",
    "\n",
    "        #create a blank dataframe for our backtest data\n",
    "        ml_backtest = pd.DataFrame()\n",
    "        ml_weights = pd.DataFrame()\n",
    "\n",
    "        #iterate through each symbol and run the backtest on the symbol\n",
    "        for ticker in inputs.keys():\n",
    "\n",
    "            count = 0\n",
    "\n",
    "            #instantiate a dataframe for our backtest outputs for one ticker. we can only run the backtest on the index of \n",
    "            #the inputs. we remove the lookback period for analysis\n",
    "            \n",
    "            backtest = pd.DataFrame()\n",
    "            weights = pd.DataFrame()\n",
    "            \n",
    "            #iterate through the inputs\n",
    "            for ix, row in inputs[ticker].iterrows(): \n",
    "\n",
    "                if count >= lookback_backtest:\n",
    "                    #the analysis df does not include the current row\n",
    "                    analysis = inputs[ticker][count-lookback_backtest:count]\n",
    "\n",
    "                    #the y var is the binary returns of the ticker\n",
    "                    y = outputs[ticker].loc[analysis.index][1:].copy()\n",
    "                    #the x var is the returns for the ticker on the analysis index lagged by 1\n",
    "                    x = inputs[ticker].loc[analysis.index].shift(1)[1:].copy()\n",
    "                    #test x represents the yesterdays x value, this is for the outsample prediction on y\n",
    "                    test_x = inputs[ticker].loc[analysis.index].tail(1)\n",
    "                    #to run a single classifier\n",
    "                    if ensemble == 'no':\n",
    "                        for name in input_classifiers:\n",
    "                            #fit the classifier to the inputs\n",
    "                            clf = classifiers[name]\n",
    "                            clf.fit(x.to_numpy(), y.values.ravel())\n",
    "                            #make a prediction on the input features \n",
    "                            predict = clf.predict(x.to_numpy())\n",
    "                            predict = pd.DataFrame(data = predict, index = y.index, columns = ['predict'])\n",
    "                            #mse = np.sum((y.values - predict.values.T)**2)\n",
    "                            #predict the last observation in the feature set to predict y tomorrow\n",
    "                            outsample = clf.predict(test_x.to_numpy())[0]\n",
    "                        #if the classifier is one. we long the security times the leverage\n",
    "                        if trade_type == 'both':\n",
    "                            if outsample == 1.0:\n",
    "                                backtest.loc[ix, ticker]  = returns.loc[ix, ticker] * lev\n",
    "                                weights.loc[ix, ticker] = 1.0\n",
    "                            #if the classifier is 0 we can choose to short the security or be long only\n",
    "                            else:\n",
    "                                backtest.loc[ix, ticker]  = -returns.loc[ix, ticker] * lev\n",
    "                                weights.loc[ix, ticker] = -1.0\n",
    "                                \n",
    "                        elif trade_type == 'short':\n",
    "                            if outsample == 1.0:\n",
    "                                backtest.loc[ix, ticker]  = np.nan\n",
    "                                weights.loc[ix, ticker] = np.nan\n",
    "                            #if the classifier is 0 we can choose to short the security or be long only\n",
    "                            else:\n",
    "                                backtest.loc[ix, ticker]  = -returns.loc[ix, ticker] * lev\n",
    "                                weights.loc[ix, ticker] = -1.0\n",
    "                                \n",
    "                        elif trade_type == 'long':\n",
    "                            if outsample == 1.0:\n",
    "                                backtest.loc[ix, ticker]  = returns.loc[ix, ticker] * lev\n",
    "                                weights.loc[ix, ticker] = 1.0\n",
    "                            #if the classifier is 0 we can choose to short the security or be long only\n",
    "                            else:\n",
    "                                backtest.loc[ix, ticker]  = np.nan\n",
    "                                weights.loc[ix, ticker] = np.nan\n",
    "                        else:\n",
    "                            backtest.loc[ix, ticker]  = np.nan\n",
    "                            weights.loc[ix, ticker] = np.nan\n",
    "                            \n",
    "                    #to do the voting method on all the classifiers\n",
    "                    else:\n",
    "                        all_outsample = []\n",
    "                        for name in input_classifiers:\n",
    "                            clf = classifiers[name]\n",
    "                            clf.fit(x.to_numpy(), y.values.ravel())\n",
    "                            predict = clf.predict(x.to_numpy())\n",
    "                            predict = pd.DataFrame(data = predict, index = y.index, columns = ['predict'])\n",
    "                            #mse = np.sum((y.values - predict.values.T)**2)\n",
    "                            outsample = clf.predict(test_x.to_numpy())[0]\n",
    "                            all_outsample.append(outsample)\n",
    "                        #take the average of the classfier outputs \n",
    "                        avg = sum(all_outsample) / len(all_outsample)  \n",
    "                        #if greater than .5, then go long the security. this paramber could be optimized\n",
    "                        if avg >= 0.5:\n",
    "                            backtest.loc[ix, ticker]  = returns.loc[ix, ticker] * lev\n",
    "                            weights.loc[ix, ticker] = 1.0\n",
    "                            \n",
    "                        #if the classifier is 0 we can choose to short the security or be long only\n",
    "                        else:\n",
    "                            backtest.loc[ix, ticker]  = -returns.loc[ix, ticker] * lev\n",
    "                            weights.loc[ix, ticker] = -1.0\n",
    "                count = count + 1\n",
    "                \n",
    "            #concatentate the backtest for one ticker with the rest to give the portfolio. \n",
    "            if ml_backtest.empty:\n",
    "                ml_backtest = backtest.copy()\n",
    "                ml_weights = weights.copy()\n",
    "            else:\n",
    "                ml_backtest = pd.concat([ml_backtest, backtest], axis = 1)\n",
    "                ml_weights = pd.concat([ml_weights, weights], axis = 1)\n",
    "\n",
    "        #return a dataframe of all the backtests on input tickers\n",
    "        return ml_backtest, ml_weights\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_factors = pd.read_csv('F-F_Research_Data_5_Factors_2x3.csv', index_col = 0)\n",
    "ff_factors.index = pd.to_datetime(ff_factors.index, format= '%Y%m')\n",
    "ff_factors = ff_factors / 100.0\n",
    "\n",
    "factor_model = ff_factors.copy()\n",
    "factor_model = factor_model[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']]\n",
    "rf = ff_factors[['RF']]\n",
    "\n",
    "index_symbol = 'Mkt-RF'\n",
    "\n",
    "print(ff_factors.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start date for data\n",
    "start = '2004-01-01'\n",
    "#end date for data\n",
    "end = '2020-01-01'\n",
    "\n",
    "#the lookback for alpha feature\n",
    "lookback = 60\n",
    "#control the leverage\n",
    "lev = 1.\n",
    "stk_symbols  = factor_model.columns\n",
    "returns = factor_model.copy()\n",
    "\n",
    "\n",
    "#set the backtest parameters\n",
    "bp = BacktestParameters(stk_symbols, start, end, lookback, lev  )\n",
    "bt = Backtest(bp, returns, mode = 'insample')\n",
    "d = Data(bp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the alpha dataframe\n",
    "df_alpha = returns[lookback:].copy()\n",
    "#initialize the idiosyncratic volatility as well\n",
    "idiosyncratic_vol = returns[lookback:].copy()\n",
    "\n",
    "count = 0\n",
    "#iterate through the monthly data. At each point in time we find the insample alpha and idiosyncratic vol\n",
    "for ix, row in returns.iterrows(): \n",
    "    #check to make sure we have at least the lookback for analysis\n",
    "    if count >= lookback:\n",
    "        \"\"\"\n",
    "        note that python will not return the last part of the index. We want to by inclusive of this\n",
    "        since this is an insample measure\n",
    "        \"\"\"\n",
    "        analysis = returns[count-lookback:count]\n",
    "\n",
    "        for ticker in returns.columns:\n",
    "                #the dependent variable is our security and index var is the independent var\n",
    "            try:\n",
    "                y = pd.concat([analysis[ticker], rf.loc[analysis.index]], axis = 1)\n",
    "                y = pd.DataFrame(y[ticker] - y[rf.columns[0]], columns = [ticker])\n",
    "                # the index is your independent variable\n",
    "                x = factor_model.loc[analysis.index].drop(ticker, axis = 1)\n",
    "                #add a constant so we can get the alpha\n",
    "                x = sm.add_constant(x)\n",
    "                x = x.shift(1)\n",
    "                \n",
    "                #use simple ols\n",
    "                mod = sm.OLS(y, x, missing='drop')\n",
    "                res = mod.fit()\n",
    "                #get the alpha\n",
    "                alpha = res.params['const']\n",
    "                #add the results to the alpha dataframe for analysis later\n",
    "                df_alpha.loc[ix, ticker] = alpha\n",
    "                #the line below is in case I want to analyze a simple difference \n",
    "                #df_alpha.loc[ix, ticker] = (analysis[ticker] - analysis[index_security ]).mean()\n",
    "                #find the idiosyncratic volatility. Simply the residual squared. Note this is monthly\n",
    "                idiosyncratic_vol.loc[ix, ticker] = res.resid.std()\n",
    "            except:\n",
    "                #if we have missing data we populate our analysis dataframe with null values \n",
    "                df_alpha.loc[ix, ticker] = np.nan\n",
    "                idiosyncratic_vol.loc[ix, ticker] = np.nan\n",
    "    #iterate to the next point in our data\n",
    "    count = count + 1\n",
    "\n",
    "#notice that I populated the alpha and idiosyncratic volatility with the full returns dataframe. \n",
    "#these two lines remove the lookback period for clean reading\n",
    "df_alpha = df_alpha.dropna(axis = 0, how = 'all')\n",
    "df_alpha = df_alpha.shift(1).dropna()\n",
    "idiosyncratic_vol = idiosyncratic_vol.dropna(axis = 0, how = 'all')\n",
    "binary_alpha = d.get_binary(df_alpha)\n",
    "\n",
    "print(df_alpha.head(5))\n",
    "print(idiosyncratic_vol.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the next few lines are a variety of feature to use\n",
    "\n",
    "#get the rolling means of returns as a momentum feature. Subtract the last month's return\n",
    "#12 month momentum factor\n",
    "rolling_mean_12 = ((returns.rolling(window = 12).mean() - returns.rolling(window = 1).mean()) )[12:]\n",
    "#6 month momentum factor\n",
    "rolling_mean_6 = ((returns.rolling(window = 6).mean() - returns.rolling(window = 1).mean()) )[6:]\n",
    "\n",
    "rolling_std_12 = (returns.rolling(window = 12).std() )[12:]\n",
    "\n",
    "#convert the momentum factor a binary variable. The center is optimized to increase strategy sharpe\n",
    "#turns the momentum factor to a 1 if the mean average return over past 12 months is over 15%/12\n",
    "binary_mean_12 = d.get_binary(rolling_mean_12, center = 0.0/12)\n",
    "binary_mean_6 = d.get_binary(rolling_mean_6, center = 0.0/12)\n",
    "#convert the output feature to a binary variable for training the classifiers\n",
    "binary_returns = d.get_binary(returns, center = 0.0/12)\n",
    "\n",
    "#creates a dictionary of different features for analysis based on ticker keys\n",
    "feature_list = [binary_alpha]\n",
    "\n",
    "feature_set = {}\n",
    "\n",
    "for i in feature_list:\n",
    "    i = i.dropna(axis = 0, how = 'all')\n",
    "    for j in i.columns:\n",
    "        if j not in feature_set.keys():\n",
    "            i[j].rename('0', inplace = True)\n",
    "            feature_set[j] = pd.DataFrame(i[j].copy())\n",
    "        else:\n",
    "            i[j].rename(str(len(feature_set[j].columns)), inplace = True)\n",
    "            feature_set[j] = pd.concat([feature_set[j], i[j].copy()], axis = 1).dropna(axis = 0, how = 'any')\n",
    "        #remove rows where we do not have features for the whole portfolio.\n",
    "        feature_set[j].dropna(axis = 0, how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest, weights = bt.run_backtest(input_classifiers= [\"Nearest Neighbors\"], lookback_backtest = 12, inputs = feature_set, outputs = binary_returns,  ensemble = 'no', trade_type = 'both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.factor_results(backtest, factor_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest.mean(axis = 1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest, weights = bt.run_backtest(input_classifiers= [\"Nearest Neighbors\"], lookback_backtest = 12, inputs = feature_set, outputs = binary_returns,  ensemble = 'no', trade_type = 'long')\n",
    "bt.factor_results(backtest, factor_model)\n",
    "backtest.mean(axis = 1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest, weights = bt.run_backtest(input_classifiers= [\"Nearest Neighbors\"], lookback_backtest = 12, inputs = feature_set, outputs = binary_returns,  ensemble = 'no', trade_type = 'short')\n",
    "bt.factor_results(backtest, factor_model)\n",
    "backtest.mean(axis = 1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest, weights = bt.run_backtest(input_classifiers= [\"Neural Net\"], lookback_backtest = 12, inputs = feature_set, outputs = binary_returns,  ensemble = 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.factor_results(backtest, factor_model)\n",
    "backtest.mean(axis = 1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_model.mean(axis = 1).mean() / factor_model.mean(axis = 1).std()\n",
    "backtest.mean(axis = 1).mean() / backtest.mean(axis = 1).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest, weights = bt.run_backtest(input_classifiers= [\"Neural Net\"], lookback_backtest = 12, inputs = feature_set, outputs = binary_returns,  ensemble = 'no', trade_type = 'long')\n",
    "bt.factor_results(backtest, factor_model)\n",
    "backtest.mean(axis = 1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest, weights = bt.run_backtest(input_classifiers= [\"Neural Net\"], lookback_backtest = 12, inputs = feature_set, outputs = binary_returns,  ensemble = 'no', trade_type = 'short')\n",
    "bt.factor_results(backtest, factor_model)\n",
    "backtest.mean(axis = 1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest, weights = bt.run_backtest(input_classifiers= [\"Random Forest\"], lookback_backtest = 12, inputs = feature_set, outputs = binary_returns,  ensemble = 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.factor_results(backtest, factor_model)\n",
    "backtest.mean(axis = 1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest, weights = bt.run_backtest(input_classifiers= [\"Random Forest\"], lookback_backtest = 12, inputs = feature_set, outputs = binary_returns,  ensemble = 'no', trade_type = 'long')\n",
    "bt.factor_results(backtest, factor_model)\n",
    "backtest.mean(axis = 1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest, weights = bt.run_backtest(input_classifiers= [\"Random Forest\"], lookback_backtest = 12, inputs = feature_set, outputs = binary_returns,  ensemble = 'no', trade_type = 'short')\n",
    "bt.factor_results(backtest, factor_model)\n",
    "backtest.mean(axis = 1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest, weights = bt.run_backtest(input_classifiers= [\"Nearest Neighbors\", \"Random Forest\"], lookback_backtest = 12, inputs = feature_set, outputs = binary_returns,  ensemble = 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.factor_results(backtest, factor_model)\n",
    "backtest.mean(axis = 1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in factor_model.columns:\n",
    "    plot_df = pd.concat([backtest[var].cumsum(), weights[var]], axis = 1)\n",
    "    plot_df.columns = ['backtest', 'signal']\n",
    "    plot_df.plot()\n",
    "    returns.loc[weights.index, var].cumsum().plot(legend = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the Market with New Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.check_new_factor(backtest, factor_model, index_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Binary Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alpha_shift = df_alpha.shift(1).dropna(axis = 0)\n",
    "backtest = returns.loc[df_alpha_shift.index]\n",
    "weights = returns.loc[df_alpha_shift.index]\n",
    "for count, row in  backtest.iterrows(): \n",
    "    for j in backtest.columns:\n",
    "        if df_alpha_shift.loc[count, j] >= 0:\n",
    "            backtest.loc[count, j] = backtest.loc[count, j]\n",
    "            weights.loc[count, j] = 1.0\n",
    "        else:\n",
    "            backtest.loc[count, j] = -backtest.loc[count, j]\n",
    "            weights.loc[count, j] = -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest.mean(axis = 1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in factor_model.columns:\n",
    "    plot_df = pd.concat([backtest[var].cumsum(), weights[var]], axis = 1)\n",
    "    plot_df.columns = ['backtest', 'signal']\n",
    "    plot_df.plot()\n",
    "    returns.loc[weights.index, var].cumsum().plot(legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.factor_results(backtest, factor_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.check_new_factor(backtest, factor_model, index_symbol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
