{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from lxml import html\n",
    "import requests\n",
    "import re\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input the CIK list for the fund family you are looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_name = 'blackrock'\n",
    "\n",
    "\n",
    "CIK_LIST = ['844779', '1398078', '774013', '1062806', '1026144', '1062805', '276463', '1097077', '1137391', '1160864', '1181249', '1159038', '353281', '834237', '97098', '216557', '765199', '814507', '790525', '110055', '1159040', '1137393', '1176194', '877151', '1169029', '1167467', '319108', '1051003', '1137440', '1167470','230382','1097293']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_wd = os.getcwd()\n",
    "if 'trunk' in cur_wd:\n",
    "    output_directory = os.path.join(\"\\\\\".join(cur_wd.split('\\\\')[0:-1]),'output')\n",
    "else:\n",
    "    output_directory = os.path.join(\"\\\\\".join(cur_wd.split('\\\\')[0:-1]),'output','working')\n",
    "    \n",
    "cur_wd = os.path.join(\"\\\\\".join(cur_wd.split('\\\\')[0:-1]),'data')\n",
    "print('data directory')\n",
    "print(cur_wd)\n",
    "print('output directory')\n",
    "print(output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned(lines):\n",
    "    cleaned = []\n",
    "    for i in lines:\n",
    "        #gets rid of tags\n",
    "        cleaned_i = re.sub('<[^>]*>', ' ', i)\n",
    "        #gets rid of &nbsp; and replaces with space\n",
    "        cleaned_i = re.sub('&nbsp;', ' ', cleaned_i)\n",
    "        #re.sub(\"<.*?>\",\"\",st)\n",
    "        if not re.match(r'^\\s*$', cleaned_i):\n",
    "            cleaned.append(cleaned_i)\n",
    "    return cleaned\n",
    "\n",
    "def find(s, ch):\n",
    "    return [i for i, ltr in enumerate(s) if ltr == ch]\n",
    "\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString))\n",
    "\n",
    "\n",
    "def remove_junk(addline):\n",
    "    addline = re.sub('<[^>]*>', ' ', addline)\n",
    "    addline = re.sub('&nbsp;', ' ', addline)\n",
    "    addline = re.sub('&#174;', ' ', addline)\n",
    "    addline = re.sub('&#8480;', ' ', addline)\n",
    "    addline = re.sub(r'&reg;',' ',addline)\n",
    "    addline = re.sub(r'\\n', ' ', addline)\n",
    "    addline = re.sub(r'\\t', ' ', addline)\n",
    "    return addline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblink = {}\n",
    "for CIK in CIK_LIST:\n",
    "    weblink[CIK]  = []\n",
    "    txt_files = os.listdir(os.path.join(cur_wd, CIK, 'n-q'))\n",
    "    for i in txt_files:\n",
    "        weblink[CIK].append(r\"https://www.sec.gov/Archives/edgar/data/\" + str(CIK)+r\"/\"  + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get panel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel2 = pd.DataFrame()\n",
    "error_panel2 = []\n",
    "\n",
    "    \n",
    "for CIK in CIK_LIST:\n",
    "    txt_files = os.listdir(os.path.join(cur_wd, CIK, 'n-q'))\n",
    "    \n",
    "    for i in txt_files:\n",
    "        if '.csv' not in i:\n",
    "            try:\n",
    "                series = {}\n",
    "                series_keys = ['SERIES-ID', 'OWNER-CIK', 'SERIES-NAME']\n",
    "                for s in series_keys:\n",
    "                    series[s] = []\n",
    "\n",
    "                contract = {}\n",
    "                contract_keys = ['CLASS-CONTRACT-ID','CLASS-CONTRACT-NAME','CLASS-CONTRACT-TICKER-SYMBOL', 'LAST-READ-SERIES']\n",
    "                for c in contract_keys:\n",
    "                    contract[c] = []\n",
    "\n",
    "                uncleaned_file = open(os.path.join(cur_wd, CIK, 'n-q',i), mode='r') \n",
    "                for u in uncleaned_file:\n",
    "                    \n",
    "\n",
    "                    if 'COMPANY CONFORMED NAME' in u:\n",
    "                        conformed_name = u.replace('COMPANY CONFORMED NAME:', '').strip()\n",
    "\n",
    "                    if 'FILED AS OF DATE:' in u:\n",
    "                        filed_date = str(u).replace('FILED AS OF DATE:','').strip()\n",
    "\n",
    "                    #series information\n",
    "                    for s in series_keys:\n",
    "                        if s in u:\n",
    "                                series[s].append(str(u).replace('<' + s + '>', \"\").strip())\n",
    "                    for c in contract_keys:\n",
    "                        if c != 'LAST-READ-SERIES':\n",
    "                            if c in u:\n",
    "                                contract[c].append(str(u).replace('<' + c + '>', \"\").strip())\n",
    "                                if c == 'CLASS-CONTRACT-ID':\n",
    "                                    contract['LAST-READ-SERIES'].append(series['SERIES-ID'][-1])\n",
    "\n",
    "\n",
    "                series = pd.DataFrame.from_dict(series, orient = 'index').T\n",
    "                contract = pd.DataFrame.from_dict(contract, orient = 'index').T\n",
    "\n",
    "\n",
    "                for s in series_keys:\n",
    "                    contract.loc[:, s] = ''\n",
    "\n",
    "                for ix,row in contract.iterrows():\n",
    "                    for s in series_keys:\n",
    "                        contract.loc[contract.index == ix, s] = series.loc[series['SERIES-ID'] == row['LAST-READ-SERIES'],s].values[0]\n",
    "                contract.loc[:,'file_read'] = i\n",
    "                contract.loc[:,'date_filed'] = filed_date\n",
    "                contract.loc[:, 'company conformed name'] = conformed_name\n",
    "                contract = contract.drop(['LAST-READ-SERIES'], axis=1)\n",
    "\n",
    "                if panel2.empty:\n",
    "                    panel2 = contract.copy()\n",
    "                else:\n",
    "                    panel2 = pd.concat([panel2, contract], axis = 0)\n",
    "            except ValueError:\n",
    "                url = r'https://www.sec.gov/Archives/edgar/data/' + CIK + r'/' + i\n",
    "                error_panel2.append(url)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(panel2)\n",
    "panel2.to_csv(os.path.join(output_directory, fund_name + '_panel2.csv'), sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on One FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CIK  ='774013'\n",
    "text =  '0001171200-09-000205.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r'https://www.sec.gov/Archives/edgar/data/' + CIK + r'/' + text.replace('.txt', '').replace('-','')  + r'/' + text\n",
    "print(url)\n",
    "tables = pd.read_html(url)\n",
    "print(len(tables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url=r'https://www.sec.gov/Archives/edgar/data/' + CIK +  r'/' + text\n",
    "\n",
    "# Make a GET request to fetch the raw HTML content\n",
    "html_content = requests.get(url).text\n",
    "\n",
    "# Parse the html content\n",
    "soup = BeautifulSoup(html_content, \"lxml\")\n",
    "#print(soup.prettify()) # print the parsed data of html\n",
    "\n",
    "table_tags = soup.find_all(\"table\")\n",
    "table = []\n",
    "\n",
    "for i in table_tags:\n",
    "    print(table_tags)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tables[0].dropna(axis = 0, how = 'all')\n",
    "df = df.dropna(axis = 0, subset = [df.columns[0]])\n",
    "cleaned_df = pd.DataFrame()\n",
    "df = df.dropna(thresh = 3, axis = 0)\n",
    "headername = ''\n",
    "for count, row in df.iterrows():\n",
    "    name = row[0]\n",
    "    if ':' in name:\n",
    "        headername = name\n",
    "    if name.split(' ')[0] == 'Series' or name[0].isdigit():\n",
    "        name = headername + ' ' + name\n",
    "        \n",
    "    if len(row.dropna().values) < 3:\n",
    "        print(row)\n",
    "        \n",
    "    add = pd.DataFrame(row[1:].dropna())\n",
    "    add = add[~add[add.columns[0]].str.contains('\\D+')]\n",
    "    if len(add) == 2:\n",
    "        add = add.transpose().dropna()\n",
    "        add.columns = ['holdings shares', 'holdings value']\n",
    "        add['holdings name'] = name\n",
    "        \n",
    "        cleaned_df = pd.concat([cleaned_df, add], axis = 0, sort = False)\n",
    "        \n",
    "cleaned_df.index = pd.RangeIndex(len(cleaned_df.index))\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for df in tables:\n",
    "    df = df.dropna(axis = 0, how = 'all')\n",
    "    df = df.dropna(axis = 1, how = 'all')\n",
    "    \n",
    "    if not df.empty:\n",
    "        print('count')\n",
    "        print(count)\n",
    "        print(' ')\n",
    "        print(df)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report_fund(df):\n",
    "    reportdate = ''\n",
    "    fundname = ''\n",
    "    \n",
    "    col_count = 0\n",
    "    for col in df.columns:\n",
    "        check_name = df[col][df[col].apply(lambda x: re.sub(r'\\s', '', str(x)).lower()).str.contains('scheduleofinvestments')]\n",
    "        if len(check_name) >= 1:\n",
    "            check_name_ix = check_name.index[0]\n",
    "            if 'continued' not in str(df.loc[df.index == check_name_ix, col].values[0]) and 'audited' in str(df.loc[df.index == check_name_ix, col].values[0]):\n",
    "                reportdate = str(df.loc[df.index == check_name_ix, col].values[0])\n",
    "                reportdate = re.sub(r'\\s', '',reportdate.encode('ascii','ignore').decode().lower()).replace(r'(unaudited)',\"\").replace(r'schedule',\"\").replace(r'of',\"\").replace(r'investments',\"\")\n",
    "\n",
    "                fundname = str(df.loc[df.index == check_name_ix, df.columns[col_count + 1]].values[0])\n",
    "                fundname = re.sub(r'\\s', '',fundname.encode('ascii','ignore').decode().lower()).replace('(percentagesshownarebasedonnetassets)', '')\n",
    "\n",
    "        col_count = col_count + 1\n",
    "    return reportdate, fundname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_level_columns(df):\n",
    "    check_found = False\n",
    "    for col in df.columns:\n",
    "        check_name = df[col][df[col].apply(lambda x: re.sub(r'\\s', '', str(x)).lower()).str.contains('level1')]\n",
    "        if len(check_name) > 0:\n",
    "            check_found = True\n",
    "    return check_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holdings(df, reportdate, fundname, headername):\n",
    "    \n",
    "    cleaned_df = pd.DataFrame()\n",
    "\n",
    "    check_level = check_level_columns(df)\n",
    "\n",
    "    if len(df) > 2 and len(df.columns) >= 3 and not check_level:\n",
    "\n",
    "        for count, row in df.iterrows():\n",
    "            name = str(row[0])\n",
    "            if ':' in name:\n",
    "                headername = name\n",
    "            if name.split(' ')[0] == 'Series' or name[0].isdigit():\n",
    "                name = headername + ' ' + name\n",
    "\n",
    "            add = pd.DataFrame(row[1:].dropna())\n",
    "            add = add[~add[add.columns[0]].str.contains('\\D+', na=False)]\n",
    "\n",
    "            if name[-1] != r'%' and name != 'adr' and name != 'class' and name != 'securities' \\\n",
    "            and name != 'total' and name != 'affiliate':\n",
    "\n",
    "                if len(add) == 2:\n",
    "                    add = add.transpose().dropna()\n",
    "                    add.columns = ['holdings shares', 'holdings value']\n",
    "                    add['holdings name'] = name\n",
    "                    add.loc[:,'reporting_date'] = reportdate\n",
    "                    add.loc[:,'fund name'] = fundname\n",
    "                    add.loc[:, 'identifier'] = ''\n",
    "\n",
    "                    cleaned_df = pd.concat([cleaned_df, add], axis = 0, sort = False)\n",
    "                    cleaned_df.index = pd.RangeIndex(len(cleaned_df.index))\n",
    "                    \n",
    "        \n",
    "    return cleaned_df, headername\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys(holdings):\n",
    "    for count, row in holdings.iterrows():\n",
    "        keys = re.findall(r'\\([^()]*\\)', row['holdings name'])\n",
    "        keylist = ''\n",
    "        keycheck = []\n",
    "        for check in keys:\n",
    "            if len(check)<= 3:\n",
    "                keycheck.append(check)\n",
    "        if len(keys) > 0:\n",
    "            for k in keys:\n",
    "                if 'Acquired' not in k:\n",
    "                    if len(k) <= 3:\n",
    "                        keylist = keylist + k\n",
    "                        holdings.loc[count, 'holdings name'] = holdings.loc[count, 'holdings name'].replace(k,'')\n",
    "\n",
    "                else:\n",
    "                    holdings.loc[count, 'holdings name'] = holdings.loc[count, 'holdings name'].replace(k,'')\n",
    "                    holdings.loc[count, 'acq name'] = row['holdings name'].split(',')[0]\n",
    "                    acq_data = k.split(' ')\n",
    "                    holdings.loc[count, 'acq date'] = acq_data[1].replace(',','')\n",
    "                    holdings.loc[count, 'acq cost'] = ''.join(re.findall(\"\\d+\", acq_data[-1]))\n",
    "\n",
    "        holdings.loc[count, 'key'] = \",\".join(keycheck)\n",
    "    return holdings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = tables[0]\n",
    "    reportdate = ''\n",
    "    fundname = ''\n",
    "    \n",
    "    col_count = 0\n",
    "    for col in df.columns:\n",
    "        check_name = df[col][df[col].apply(lambda x: re.sub(r'\\s', '', str(x)).lower()).str.contains('scheduleofinvestments')]\n",
    "        if len(check_name) >= 1:\n",
    "            check_name_ix = check_name.index[0]\n",
    "            if 'continued' not in str(df.loc[df.index == check_name_ix, col].values[0]) and 'audited' in str(df.loc[df.index == check_name_ix, col].values[0]):\n",
    "                reportdate = str(df.loc[df.index == check_name_ix, col].values[0])\n",
    "                reportdate = re.sub(r'\\s', '',reportdate.encode('ascii','ignore').decode().lower()).replace(r'(unaudited)',\"\").replace(r'schedule',\"\").replace(r'of',\"\").replace(r'investments',\"\")\n",
    "\n",
    "                fundname = str(df.loc[df.index == check_name_ix, df.columns[col_count + 1]].values[0])\n",
    "                fundname = re.sub(r'\\s', '',fundname.encode('ascii','ignore').decode().lower()).replace('(percentagesshownarebasedonnetassets)', '')\n",
    "                print(fundname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in tables:\n",
    "    #remove all rows and columns of nas\n",
    "    df = df.dropna(axis = 0, how = 'all')\n",
    "    df = df.dropna(axis = 1, how = 'all')\n",
    "    \n",
    "    if not df.empty:\n",
    "        try:\n",
    "            reportdate, fundname = get_report_fund(df)\n",
    "            if reportdate != '':\n",
    "                print(reportdate)\n",
    "                print(fundname)\n",
    "                found = True\n",
    "        except :\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "holdings = pd.DataFrame()\n",
    "reportdate = ''\n",
    "fundname = ''\n",
    "\n",
    "legend = pd.DataFrame()\n",
    "\n",
    "identifiercount = 0\n",
    "\n",
    "headername = ''\n",
    "\n",
    "\n",
    "for df in tables:\n",
    "    #remove all rows and columns of nas\n",
    "    df = df.dropna(axis = 0, how = 'all')\n",
    "    df = df.dropna(axis = 1, how = 'all')\n",
    "    \n",
    "    if not df.empty:\n",
    "        \n",
    "        #get the report dates and fund names of this dataframe\n",
    "        reportdate_test, fundname_test = get_report_fund(df)\n",
    "        if reportdate_test != '':\n",
    "            found = True\n",
    "            reportdate = reportdate_test\n",
    "            fundname = fundname_test\n",
    "        \n",
    "        \n",
    "        \n",
    "        for count, row in df.iterrows():\n",
    "            firstrow = re.sub(r'\\s', '', str(row[df.columns[0]])).encode('ascii','ignore').decode().lower()\n",
    "            if '(' in firstrow and ')' in firstrow and len(firstrow) == 3:\n",
    "                \n",
    "                if len(holdings.loc[holdings['identifier'] == '']) > 0:\n",
    "                    identifiercount = identifiercount + 1\n",
    "                    found = False\n",
    "                    holdings.loc[holdings['identifier'] == '', 'identifier'] = text + str(identifiercount)\n",
    "                    \n",
    "                add_legend = pd.DataFrame(row).transpose()\n",
    "                add_legend.columns = ['symbol', 'code']\n",
    "                add_legend.loc[:, 'identifier'] = text + str(identifiercount)\n",
    "                \n",
    "                if len(legend) == 0:\n",
    "                    legend = add_legend.copy()\n",
    "\n",
    "                else:\n",
    "                    if add_legend['symbol'].values[0] not in legend.loc[legend['identifier'] ==\\\n",
    "                                                                    text + str(identifiercount), 'symbol'].tolist():\n",
    "                            legend = pd.concat([legend, add_legend], axis = 0)\n",
    "                    \n",
    "                    \n",
    "\n",
    "        cleaned_df, headername = get_holdings(df, reportdate, fundname, headername)\n",
    "\n",
    "\n",
    "\n",
    "        if len(cleaned_df) > 0 and found:\n",
    "            security = cleaned_df.copy()\n",
    "            security['holdings name'] = security['holdings name'].apply(lambda x: x.encode('ascii','ignore').decode())\n",
    "            if len(security) > 0:\n",
    "                if holdings.empty:\n",
    "                    holdings = security.copy()\n",
    "                else:\n",
    "                    holdings = pd.concat([holdings, security], axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "legend.index = pd.RangeIndex(len(legend.index))\n",
    "holdings.index = pd.RangeIndex(len(holdings.index))\n",
    "\n",
    "\n",
    "            \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'holdings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-13e5b06b1ffa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mholdings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'holdings' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings['value multiplier'] = ''\n",
    "holdings['key'] = ''\n",
    "holdings['textfile'] = text\n",
    "holdings['CIK'] = CIK\n",
    "holdings['acq name'] = ''\n",
    "holdings['acq date'] = ''\n",
    "holdings['acq cost'] = ''\n",
    "holdings['date_filed'] = '' \n",
    "holdings['company conformed name'] = ''\n",
    "try:\n",
    "    date_filed = panel2.loc[panel2['file_read'] == text, 'date_filed'].unique()[0]\n",
    "    conformed_name = panel2.loc[panel2['file_read'] == text, 'company conformed name'].unique()[0]\n",
    "except IndexError:\n",
    "    date_filed = ''\n",
    "    conformed_name = ''\n",
    "    \n",
    "holdings.loc[:, 'date_filed'] = date_filed\n",
    "holdings.loc[:, 'company conformed name'] = conformed_name\n",
    "\n",
    "holdings.index = pd.RangeIndex(len(holdings.index))\n",
    "print(holdings)\n",
    "\n",
    "for z in weblink[CIK]:\n",
    "    if text in z:\n",
    "        matching_link = z\n",
    "\n",
    "holdings['weblink'] = matching_link\n",
    "legend['weblink'] = matching_link\n",
    "legend['textfile'] = text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the acquisition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings = get_keys(holdings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings['identifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend.loc[:,'restricted'] = 'no'\n",
    "\n",
    "legend.loc[legend['code'].str.contains(\"restrict\") | legend['code'].str.contains(\"level 3 security\") \\\n",
    "              | legend['code'].str.contains(\"exempt from registration\"), 'restricted'] = 'yes'\n",
    "\n",
    "restricted = legend.loc[legend['restricted'].str.contains(\"yes\")]\n",
    "print(restricted)\n",
    "\n",
    "holdings.loc[:,'restricted'] = 'no'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the restricted legend and restricted securities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend.loc[:,'restricted'] = 'no'\n",
    "\n",
    "legend.loc[legend['code'].str.contains(\"restrict\") | legend['code'].str.contains(\"level 3 security\") \\\n",
    "              | legend['code'].str.contains(\"exempt from registration\"), 'restricted'] = 'yes'\n",
    "\n",
    "restricted = legend.loc[legend['restricted'].str.contains(\"yes\")]\n",
    "print(restricted)\n",
    "\n",
    "holdings.loc[:,'restricted'] = 'no'\n",
    "\n",
    "for index, row in restricted.iterrows():\n",
    "    holdings.loc[(holdings['identifier'] == row['identifier']) & (holdings['textfile'] == row.textfile) \\\n",
    "                   & (holdings['key'].str.contains(row['symbol'])), 'restricted'] = 'yes'\n",
    "    \n",
    "restricted_holdings = holdings.loc[(holdings['restricted'] == 'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the restricted holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(restricted_holdings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpanel1(CIK, text, panel2):\n",
    "    \n",
    "    url = r'https://www.sec.gov/Archives/edgar/data/' + CIK +  r'/' + text\n",
    "    tables = pd.read_html(url,encoding=\"utf-8\")\n",
    "    \n",
    "    holdings = pd.DataFrame()\n",
    "    reportdate = ''\n",
    "    fundname = ''\n",
    "\n",
    "    legend = pd.DataFrame()\n",
    "\n",
    "    identifiercount = 0\n",
    "\n",
    "    headername = ''\n",
    "\n",
    "\n",
    "    for df in tables:\n",
    "        #remove all rows and columns of nas\n",
    "        df = df.dropna(axis = 0, how = 'all')\n",
    "        df = df.dropna(axis = 1, how = 'all')\n",
    "\n",
    "        if not df.empty:\n",
    "\n",
    "            #get the report dates and fund names of this dataframe\n",
    "            reportdate_test, fundname_test = get_report_fund(df)\n",
    "            if reportdate_test != '':\n",
    "                found = True\n",
    "                reportdate = reportdate_test\n",
    "                fundname = fundname_test\n",
    "\n",
    "\n",
    "\n",
    "            for count, row in df.iterrows():\n",
    "                firstrow = re.sub(r'\\s', '', str(row[df.columns[0]])).encode('ascii','ignore').decode().lower()\n",
    "                if '(' in firstrow and ')' in firstrow and len(firstrow) == 3:\n",
    "\n",
    "                    if len(holdings.loc[holdings['identifier'] == '']) > 0:\n",
    "                        identifiercount = identifiercount + 1\n",
    "                        found = False\n",
    "                        holdings.loc[holdings['identifier'] == '', 'identifier'] = text + str(identifiercount)\n",
    "\n",
    "                    add_legend = pd.DataFrame(row).transpose()\n",
    "                    add_legend.columns = ['symbol', 'code']\n",
    "                    add_legend.loc[:, 'identifier'] = text + str(identifiercount)\n",
    "\n",
    "                    if len(legend) == 0:\n",
    "                        legend = add_legend.copy()\n",
    "\n",
    "                    else:\n",
    "                        if add_legend['symbol'].values[0] not in legend.loc[legend['identifier'] ==\\\n",
    "                                                                        text + str(identifiercount), 'symbol'].tolist():\n",
    "                                legend = pd.concat([legend, add_legend], axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "            cleaned_df, headername = get_holdings(df, reportdate, fundname, headername)\n",
    "\n",
    "\n",
    "\n",
    "            if len(cleaned_df) > 0 and found:\n",
    "                security = cleaned_df.copy()\n",
    "                security['holdings name'] = security['holdings name'].apply(lambda x: x.encode('ascii','ignore').decode())\n",
    "                if len(security) > 0:\n",
    "                    if holdings.empty:\n",
    "                        holdings = security.copy()\n",
    "                    else:\n",
    "                        holdings = pd.concat([holdings, security], axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "    legend.index = pd.RangeIndex(len(legend.index))\n",
    "    holdings.index = pd.RangeIndex(len(holdings.index))\n",
    "    \n",
    "    \n",
    "    \n",
    "    holdings['value multiplier'] = ''\n",
    "    holdings['key'] = ''\n",
    "    holdings['textfile'] = text\n",
    "    holdings['CIK'] = CIK\n",
    "    holdings['acq name'] = ''\n",
    "    holdings['acq date'] = ''\n",
    "    holdings['acq cost'] = ''\n",
    "    holdings['date_filed'] = '' \n",
    "    holdings['company conformed name'] = ''\n",
    "    \n",
    "    try:\n",
    "        date_filed = panel2.loc[panel2['file_read'] == text, 'date_filed'].unique()[0]\n",
    "        conformed_name = panel2.loc[panel2['file_read'] == text, 'company conformed name'].unique()[0]\n",
    "    except IndexError:\n",
    "        date_filed = ''\n",
    "        conformed_name = ''\n",
    "\n",
    "    holdings.loc[:, 'date_filed'] = date_filed\n",
    "    holdings.loc[:, 'company conformed name'] = conformed_name\n",
    "\n",
    "    holdings.index = pd.RangeIndex(len(holdings.index))\n",
    "\n",
    "    holdings['weblink'] = url\n",
    "    legend['weblink'] = url\n",
    "    legend['textfile'] = text\n",
    "    \n",
    "    \n",
    "    holdings = get_keys(holdings)\n",
    "        \n",
    "\n",
    "        \n",
    "    return holdings, legend\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on All CIKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel1 = pd.DataFrame()\n",
    "\n",
    "\n",
    "panel1 = pd.DataFrame()\n",
    "panel1_legend = pd.DataFrame()\n",
    "error_panel1 = []\n",
    "\n",
    "#CIK_LIST = ['319108','1097293','230382']\n",
    "\n",
    "CIK_LIST = ['844779', '1398078', '774013', '1062806', '1026144', '1062805', '276463', '1097077', '1137391', '1160864', '1181249', '1159038', '353281', '834237', '97098', '216557', '765199', '814507', '790525', '110055', '1159040', '1137393', '1176194', '877151', '1169029', '1167467', '319108', '1051003', '1137440', '1167470','230382','1097293']\n",
    "\n",
    "\n",
    "for CIK in CIK_LIST:\n",
    "    txt_files = os.listdir(os.path.join(cur_wd, CIK, 'n-q'))\n",
    "    \n",
    "    for i in txt_files:\n",
    "        if '.csv' not in i:\n",
    "            try:\n",
    "                holdings, legend = getpanel1(CIK, i, panel2)\n",
    "\n",
    "                if len(holdings) == 0:\n",
    "                    #print(i)\n",
    "                    pass\n",
    "                if panel1.empty:\n",
    "                    panel1 = holdings.copy()\n",
    "                    panel1_legend = legend.copy()\n",
    "                else:\n",
    "                    panel1 = pd.concat([panel1, holdings], axis = 0, ignore_index = True)\n",
    "                    panel1_legend = pd.concat([panel1_legend , legend], axis = 0, ignore_index = True)\n",
    "                panel1.index = pd.RangeIndex(len(panel1.index))\n",
    "            except:\n",
    "                error_panel1.append(r'https://www.sec.gov/Archives/edgar/data/' + CIK +  r'/' + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_panel1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(panel1.dropna(axis =1, how = 'all'))\n",
    "panel1.to_csv(os.path.join(output_directory, fund_name + '_panel1.csv'), sep = ',')\n",
    "panel1_legend.to_csv(os.path.join(output_directory, fund_name + '_panel1_legend.csv'), sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel1_legend.loc[:,'restricted'] = 'no'\n",
    "\n",
    "panel1_legend.loc[panel1_legend['code'].str.contains(\"restrict\") | panel1_legend['code'].str.contains(\"level 3 security\") \\\n",
    "              | panel1_legend['code'].str.contains(\"exempt from registration\"), 'restricted'] = 'yes'\n",
    "\n",
    "restricted = panel1_legend.loc[panel1_legend['restricted'].str.contains(\"yes\")]\n",
    "\n",
    "restricted.to_csv(os.path.join(output_directory, fund_name + '_panel1_restricted_legend.csv'), sep = ',')\n",
    "print(restricted)\n",
    "\n",
    "panel1.loc[:,'restricted'] = 'no'\n",
    "\n",
    "for index, row in restricted.iterrows():\n",
    "    panel1.loc[(panel1['identifier'] == row['identifier']) & (panel1['textfile'] == row.textfile) \\\n",
    "                   & (panel1['key'].str.contains(row['symbol'])), 'restricted'] = 'yes'\n",
    "    \n",
    "restricted_holdings = panel1.loc[(panel1['restricted'] == 'yes')]\n",
    "restricted_holdings.to_csv(os.path.join(output_directory, fund_name + '_panel1_restricted.csv'), sep = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
