{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from lxml import html\n",
    "import requests\n",
    "import re\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input the CIK list for the fund family you are looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nweblink = {}\\nCIK_LIST = ['24238']\\nfor CIK in CIK_LIST:\\n    my_filings = Filing(cik_lookup=CIK, filing_type=FilingType.FILING_NQ, start_date = start_date, end_date = end_date) \\n    my_filings.save(cur_wd)\\n    weblink[CIK] = my_filings.get_urls()[CIK]\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_wd = os.getcwd()\n",
    "\"\"\"\n",
    "weblink = {}\n",
    "CIK_LIST = ['24238']\n",
    "for CIK in CIK_LIST:\n",
    "    my_filings = Filing(cik_lookup=CIK, filing_type=FilingType.FILING_NQ, start_date = start_date, end_date = end_date) \n",
    "    my_filings.save(cur_wd)\n",
    "    weblink[CIK] = my_filings.get_urls()[CIK]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(s, ch):\n",
    "    return [i for i, ltr in enumerate(s) if ltr == ch]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblink = {}\n",
    "\n",
    "CIK_LIST = [ '319108','1097293']\n",
    "\n",
    "txts = []\n",
    "for CIK in CIK_LIST:\n",
    "    weblink[CIK] = []\n",
    "    direc = os.path.join(cur_wd, CIK, 'n-q')\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)\n",
    "        \n",
    "        req = Request(r\"https://www.sec.gov/Archives/edgar/data/\" + str(CIK))\n",
    "        html_page = urlopen(req)\n",
    "\n",
    "        soup = BeautifulSoup(html_page, \"lxml\")\n",
    "\n",
    "        for link in soup.findAll('a'):\n",
    "            archive = link.get('href')\n",
    "            if str('/Archives/edgar/data/') + CIK in archive:\n",
    "                req_archive = Request(r\"https://www.sec.gov\" + archive)\n",
    "\n",
    "                html_page_archive = urlopen(req_archive)\n",
    "                soup_archive = BeautifulSoup(html_page_archive, \"lxml\")\n",
    "\n",
    "                for link_archive in soup_archive.findAll('a'):\n",
    "                    txt_name = link_archive.get('href')\n",
    "                    if \".txt\" in txt_name:\n",
    "                        ixs = find(txt_name, r'/')\n",
    "                        file_name = txt_name[ixs[-1]+1:]\n",
    "                        non_dig = re.findall(r'\\D+', file_name)\n",
    "                        if len(non_dig) == 3:\n",
    "                            print(r\"https://www.sec.gov\" + txt_name)\n",
    "                            try: \n",
    "                                r = Request(r\"https://www.sec.gov\" + txt_name)\n",
    "                                read = urlopen(r)\n",
    "                                r = read.readlines()\n",
    "                                found = False\n",
    "                                #check to see if n-q file\n",
    "                                for i in r:\n",
    "                                    string_row = i.decode('utf-8').lower()\n",
    "                                    if 'conformed submission' in string_row and 'n-q'in string_row:\n",
    "                                        found = True\n",
    "                            except IncompleteRead:\n",
    "                                found = False\n",
    "                                \n",
    "                            if found:\n",
    "                                print(r\"https://www.sec.gov\" + txt_name)\n",
    "                                weblink[CIK].append(r\"https://www.sec.gov\" + txt_name)\n",
    "                                ixs = find(txt_name, r'/')\n",
    "                                file_name = txt_name[ixs[-1]+1:]\n",
    "                                f = open(os.path.join(direc, file_name), mode = 'w')\n",
    "                                for row in r:\n",
    "                                    clean_row = row.decode('utf-8')\n",
    "                                    if clean_row != '':\n",
    "                                        f.write(clean_row)\n",
    "                                f.close()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cleaned(lines):\n",
    "    cleaned = []\n",
    "    for i in lines:\n",
    "        #gets rid of tags\n",
    "        cleaned_i = re.sub('<[^>]*>', ' ', i)\n",
    "        #gets rid of &nbsp; and replaces with space\n",
    "        cleaned_i = re.sub('&nbsp;', ' ', cleaned_i)\n",
    "        #re.sub(\"<.*?>\",\"\",st)\n",
    "        if not re.match(r'^\\s*$', cleaned_i):\n",
    "            cleaned.append(cleaned_i)\n",
    "    return cleaned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblink = {}\n",
    "for CIK in CIK_LIST:\n",
    "    weblink[CIK]  = []\n",
    "    txt_files = os.listdir(os.path.join(cur_wd, CIK, 'n-q'))\n",
    "    for i in txt_files:\n",
    "        weblink[CIK].append(r\"https://www.sec.gov/Archives/edgar/data/\" + str(CIK)+r\"/\"  + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#get the needed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get panel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel2 = pd.DataFrame()\n",
    "error_panel2 = []\n",
    "\n",
    "    \n",
    "for CIK in CIK_LIST:\n",
    "    txt_files = os.listdir(os.path.join(cur_wd, CIK, 'n-q'))\n",
    "    \n",
    "    for i in txt_files:\n",
    "        if '.csv' not in i:\n",
    "            try:\n",
    "                series = {}\n",
    "                series_keys = ['SERIES-ID', 'OWNER-CIK', 'SERIES-NAME']\n",
    "                for s in series_keys:\n",
    "                    series[s] = []\n",
    "\n",
    "                contract = {}\n",
    "                contract_keys = ['CLASS-CONTRACT-ID','CLASS-CONTRACT-NAME','CLASS-CONTRACT-TICKER-SYMBOL', 'LAST-READ-SERIES']\n",
    "                for c in contract_keys:\n",
    "                    contract[c] = []\n",
    "\n",
    "                uncleaned_file = open(os.path.join(cur_wd, CIK, 'n-q',i), mode='r') \n",
    "                for u in uncleaned_file:\n",
    "                    \n",
    "\n",
    "                    if 'COMPANY CONFORMED NAME' in u:\n",
    "                        conformed_name = u.replace('COMPANY CONFORMED NAME:', '').strip()\n",
    "\n",
    "                    if 'FILED AS OF DATE:' in u:\n",
    "                        filed_date = str(u).replace('FILED AS OF DATE:','').strip()\n",
    "\n",
    "                    #series information\n",
    "                    for s in series_keys:\n",
    "                        if s in u:\n",
    "                                series[s].append(str(u).replace('<' + s + '>', \"\").strip())\n",
    "                    for c in contract_keys:\n",
    "                        if c != 'LAST-READ-SERIES':\n",
    "                            if c in u:\n",
    "                                contract[c].append(str(u).replace('<' + c + '>', \"\").strip())\n",
    "                                if c == 'CLASS-CONTRACT-ID':\n",
    "                                    contract['LAST-READ-SERIES'].append(series['SERIES-ID'][-1])\n",
    "\n",
    "\n",
    "                series = pd.DataFrame.from_dict(series, orient = 'index').T\n",
    "                contract = pd.DataFrame.from_dict(contract, orient = 'index').T\n",
    "\n",
    "\n",
    "                for s in series_keys:\n",
    "                    contract.loc[:, s] = ''\n",
    "\n",
    "                for ix,row in contract.iterrows():\n",
    "                    for s in series_keys:\n",
    "                        contract.loc[contract.index == ix, s] = series.loc[series['SERIES-ID'] == row['LAST-READ-SERIES'],s].values[0]\n",
    "                contract.loc[:,'file_read'] = i\n",
    "                contract.loc[:,'date_filed'] = filed_date\n",
    "                contract.loc[:, 'company conformed name'] = conformed_name\n",
    "                contract = contract.drop(['LAST-READ-SERIES'], axis=1)\n",
    "\n",
    "                if panel2.empty:\n",
    "                    panel2 = contract.copy()\n",
    "                else:\n",
    "                    panel2 = pd.concat([panel2, contract], axis = 0)\n",
    "            except ValueError:\n",
    "                error_panel2.append(i)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000891092-05-001030.txt', '0000891092-05-002324.txt', '0000950123-04-014132.txt', '0001193805-05-001208.txt', '0001193805-05-002396.txt', '0000900092-04-000301.txt', '0000900092-05-000097.txt', '0000900092-05-000126.txt', '0000900092-05-000444.txt']\n"
     ]
    }
   ],
   "source": [
    "print(error_panel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CLASS-CONTRACT-ID                             CLASS-CONTRACT-NAME  \\\n",
      "0         C000010829     Mercury Balanced Capital Strategy Portfolio   \n",
      "1         C000010830       Mercury Large Cap Core Strategy Portfolio   \n",
      "2         C000010831            Mercury Core Bond Strategy Portfolio   \n",
      "3         C000010832    Mercury Global Allocation Strategy Portfolio   \n",
      "4         C000010833   Mercury Fundamental Growth Strategy Portfolio   \n",
      "5         C000010834                    Mercury High Yield Portfolio   \n",
      "6         C000010835  Mercury Intermediate Government Bond Portfolio   \n",
      "7         C000010836                 Mercury Money Reserve Portfolio   \n",
      "0         C000010829            BlackRock Balanced Capital Portfolio   \n",
      "1         C000010830              BlackRock Large Cap Core Portfolio   \n",
      "2         C000010831                        BlackRock Bond Portfolio   \n",
      "3         C000010832           BlackRock Global Allocation Portfolio   \n",
      "4         C000010833          BlackRock Fundamental Growth Portfolio   \n",
      "5         C000010834                 BlackRock High Income Portfolio   \n",
      "6         C000010835           BlackRock Government Income Portfolio   \n",
      "7         C000010836                BlackRock Money Market Portfolio   \n",
      "0         C000010829            BlackRock Balanced Capital Portfolio   \n",
      "1         C000010830              BlackRock Large Cap Core Portfolio   \n",
      "2         C000010831                        BlackRock Bond Portfolio   \n",
      "3         C000010832           BlackRock Global Allocation Portfolio   \n",
      "4         C000010833          BlackRock Fundamental Growth Portfolio   \n",
      "5         C000010834                 BlackRock High Income Portfolio   \n",
      "6         C000010835           BlackRock Government Income Portfolio   \n",
      "7         C000010836                BlackRock Money Market Portfolio   \n",
      "0         C000010829            BlackRock Balanced Capital Portfolio   \n",
      "1         C000010830              BlackRock Large Cap Core Portfolio   \n",
      "2         C000010831                        BlackRock Bond Portfolio   \n",
      "3         C000010832           BlackRock Global Allocation Portfolio   \n",
      "4         C000010833          BlackRock Fundamental Growth Portfolio   \n",
      "5         C000010834                 BlackRock High Income Portfolio   \n",
      "..               ...                                             ...   \n",
      "1         C000006152                                      Investor B   \n",
      "2         C000006153                                      Investor C   \n",
      "3         C000006154                                   Institutional   \n",
      "0         C000006151                                      Investor A   \n",
      "1         C000006153                                      Investor C   \n",
      "2         C000006154                                   Institutional   \n",
      "0         C000006151                                      Investor A   \n",
      "1         C000006153                                      Investor C   \n",
      "2         C000006154                                   Institutional   \n",
      "0         C000006151                                      Investor A   \n",
      "1         C000006153                                      Investor C   \n",
      "2         C000006154                                   Institutional   \n",
      "0         C000006151                                      Investor A   \n",
      "1         C000006153                                      Investor C   \n",
      "2         C000006154                                   Institutional   \n",
      "0         C000006151                                      Investor A   \n",
      "1         C000006153                                      Investor C   \n",
      "2         C000006154                                   Institutional   \n",
      "0         C000006151                                      Investor A   \n",
      "1         C000006153                                      Investor C   \n",
      "2         C000006154                                   Institutional   \n",
      "0         C000006151                                      Investor A   \n",
      "1         C000006153                                      Investor C   \n",
      "2         C000006154                                   Institutional   \n",
      "0         C000006151                                      Investor A   \n",
      "1         C000006153                                      Investor C   \n",
      "2         C000006154                                   Institutional   \n",
      "0         C000006151                                      Investor A   \n",
      "1         C000006153                                      Investor C   \n",
      "2         C000006154                                   Institutional   \n",
      "\n",
      "   CLASS-CONTRACT-TICKER-SYMBOL   SERIES-ID   OWNER-CIK  \\\n",
      "0                          None  S000003863  0000319108   \n",
      "1                          None  S000003864  0000319108   \n",
      "2                          None  S000003865  0000319108   \n",
      "3                          None  S000003866  0000319108   \n",
      "4                          None  S000003867  0000319108   \n",
      "5                          None  S000003868  0000319108   \n",
      "6                          None  S000003869  0000319108   \n",
      "7                          None  S000003870  0000319108   \n",
      "0                          None  S000003863  0000319108   \n",
      "1                          None  S000003864  0000319108   \n",
      "2                          None  S000003865  0000319108   \n",
      "3                          None  S000003866  0000319108   \n",
      "4                          None  S000003867  0000319108   \n",
      "5                          None  S000003868  0000319108   \n",
      "6                          None  S000003869  0000319108   \n",
      "7                          None  S000003870  0000319108   \n",
      "0                          None  S000003863  0000319108   \n",
      "1                          None  S000003864  0000319108   \n",
      "2                          None  S000003865  0000319108   \n",
      "3                          None  S000003866  0000319108   \n",
      "4                          None  S000003867  0000319108   \n",
      "5                          None  S000003868  0000319108   \n",
      "6                          None  S000003869  0000319108   \n",
      "7                          None  S000003870  0000319108   \n",
      "0                          None  S000003863  0000319108   \n",
      "1                          None  S000003864  0000319108   \n",
      "2                          None  S000003865  0000319108   \n",
      "3                          None  S000003866  0000319108   \n",
      "4                          None  S000003867  0000319108   \n",
      "5                          None  S000003868  0000319108   \n",
      "..                          ...         ...         ...   \n",
      "1                          None  S000002344  0001097293   \n",
      "2                          None  S000002344  0001097293   \n",
      "3                          None  S000002344  0001097293   \n",
      "0                          None  S000002344  0001097293   \n",
      "1                          None  S000002344  0001097293   \n",
      "2                          None  S000002344  0001097293   \n",
      "0                          None  S000002344  0001097293   \n",
      "1                          None  S000002344  0001097293   \n",
      "2                          None  S000002344  0001097293   \n",
      "0                          None  S000002344  0001097293   \n",
      "1                          None  S000002344  0001097293   \n",
      "2                          None  S000002344  0001097293   \n",
      "0                          None  S000002344  0001097293   \n",
      "1                          None  S000002344  0001097293   \n",
      "2                          None  S000002344  0001097293   \n",
      "0                          None  S000002344  0001097293   \n",
      "1                          None  S000002344  0001097293   \n",
      "2                          None  S000002344  0001097293   \n",
      "0                          None  S000002344  0001097293   \n",
      "1                          None  S000002344  0001097293   \n",
      "2                          None  S000002344  0001097293   \n",
      "0                          None  S000002344  0001097293   \n",
      "1                          None  S000002344  0001097293   \n",
      "2                          None  S000002344  0001097293   \n",
      "0                          None  S000002344  0001097293   \n",
      "1                          None  S000002344  0001097293   \n",
      "2                          None  S000002344  0001097293   \n",
      "0                          None  S000002344  0001097293   \n",
      "1                          None  S000002344  0001097293   \n",
      "2                          None  S000002344  0001097293   \n",
      "\n",
      "                                       SERIES-NAME                 file_read  \\\n",
      "0      Mercury Balanced Capital Strategy Portfolio  0000891092-06-001367.txt   \n",
      "1        Mercury Large Cap Core Strategy Portfolio  0000891092-06-001367.txt   \n",
      "2             Mercury Core Bond Strategy Portfolio  0000891092-06-001367.txt   \n",
      "3     Mercury Global Allocation Strategy Portfolio  0000891092-06-001367.txt   \n",
      "4    Mercury Fundamental Growth Strategy Portfolio  0000891092-06-001367.txt   \n",
      "5                     Mercury High Yield Portfolio  0000891092-06-001367.txt   \n",
      "6   Mercury Intermediate Government Bond Portfolio  0000891092-06-001367.txt   \n",
      "7                  Mercury Money Reserve Portfolio  0000891092-06-001367.txt   \n",
      "0             BlackRock Balanced Capital Portfolio  0000891092-06-003630.txt   \n",
      "1               BlackRock Large Cap Core Portfolio  0000891092-06-003630.txt   \n",
      "2                         BlackRock Bond Portfolio  0000891092-06-003630.txt   \n",
      "3            BlackRock Global Allocation Portfolio  0000891092-06-003630.txt   \n",
      "4           BlackRock Fundamental Growth Portfolio  0000891092-06-003630.txt   \n",
      "5                  BlackRock High Income Portfolio  0000891092-06-003630.txt   \n",
      "6            BlackRock Government Income Portfolio  0000891092-06-003630.txt   \n",
      "7                 BlackRock Money Market Portfolio  0000891092-06-003630.txt   \n",
      "0             BlackRock Balanced Capital Portfolio  0000891092-07-002151.txt   \n",
      "1               BlackRock Large Cap Core Portfolio  0000891092-07-002151.txt   \n",
      "2                         BlackRock Bond Portfolio  0000891092-07-002151.txt   \n",
      "3            BlackRock Global Allocation Portfolio  0000891092-07-002151.txt   \n",
      "4           BlackRock Fundamental Growth Portfolio  0000891092-07-002151.txt   \n",
      "5                  BlackRock High Income Portfolio  0000891092-07-002151.txt   \n",
      "6            BlackRock Government Income Portfolio  0000891092-07-002151.txt   \n",
      "7                 BlackRock Money Market Portfolio  0000891092-07-002151.txt   \n",
      "0             BlackRock Balanced Capital Portfolio  0000891092-07-005174.txt   \n",
      "1               BlackRock Large Cap Core Portfolio  0000891092-07-005174.txt   \n",
      "2                         BlackRock Bond Portfolio  0000891092-07-005174.txt   \n",
      "3            BlackRock Global Allocation Portfolio  0000891092-07-005174.txt   \n",
      "4           BlackRock Fundamental Growth Portfolio  0000891092-07-005174.txt   \n",
      "5                  BlackRock High Income Portfolio  0000891092-07-005174.txt   \n",
      "..                                             ...                       ...   \n",
      "1                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-14-277011.txt   \n",
      "2                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-14-277011.txt   \n",
      "3                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-14-277011.txt   \n",
      "0                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-15-017142.txt   \n",
      "1                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-15-017142.txt   \n",
      "2                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-15-017142.txt   \n",
      "0                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-15-261044.txt   \n",
      "1                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-15-261044.txt   \n",
      "2                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-15-261044.txt   \n",
      "0                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-16-435585.txt   \n",
      "1                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-16-435585.txt   \n",
      "2                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-16-435585.txt   \n",
      "0                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-16-658386.txt   \n",
      "1                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-16-658386.txt   \n",
      "2                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-16-658386.txt   \n",
      "0                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-17-016188.txt   \n",
      "1                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-17-016188.txt   \n",
      "2                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-17-016188.txt   \n",
      "0                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-17-233981.txt   \n",
      "1                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-17-233981.txt   \n",
      "2                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-17-233981.txt   \n",
      "0                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-18-016121.txt   \n",
      "1                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-18-016121.txt   \n",
      "2                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-18-016121.txt   \n",
      "0                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-18-223546.txt   \n",
      "1                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-18-223546.txt   \n",
      "2                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-18-223546.txt   \n",
      "0                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-19-013629.txt   \n",
      "1                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-19-013629.txt   \n",
      "2                BLACKROCK FOCUS GROWTH FUND, INC.  0001193125-19-013629.txt   \n",
      "\n",
      "   date_filed             company conformed name  \n",
      "0    20060530              FAM Series Fund, Inc.  \n",
      "1    20060530              FAM Series Fund, Inc.  \n",
      "2    20060530              FAM Series Fund, Inc.  \n",
      "3    20060530              FAM Series Fund, Inc.  \n",
      "4    20060530              FAM Series Fund, Inc.  \n",
      "5    20060530              FAM Series Fund, Inc.  \n",
      "6    20060530              FAM Series Fund, Inc.  \n",
      "7    20060530              FAM Series Fund, Inc.  \n",
      "0    20061128        BlackRock Series Fund, Inc.  \n",
      "1    20061128        BlackRock Series Fund, Inc.  \n",
      "2    20061128        BlackRock Series Fund, Inc.  \n",
      "3    20061128        BlackRock Series Fund, Inc.  \n",
      "4    20061128        BlackRock Series Fund, Inc.  \n",
      "5    20061128        BlackRock Series Fund, Inc.  \n",
      "6    20061128        BlackRock Series Fund, Inc.  \n",
      "7    20061128        BlackRock Series Fund, Inc.  \n",
      "0    20070530        BlackRock Series Fund, Inc.  \n",
      "1    20070530        BlackRock Series Fund, Inc.  \n",
      "2    20070530        BlackRock Series Fund, Inc.  \n",
      "3    20070530        BlackRock Series Fund, Inc.  \n",
      "4    20070530        BlackRock Series Fund, Inc.  \n",
      "5    20070530        BlackRock Series Fund, Inc.  \n",
      "6    20070530        BlackRock Series Fund, Inc.  \n",
      "7    20070530        BlackRock Series Fund, Inc.  \n",
      "0    20071129        BlackRock Series Fund, Inc.  \n",
      "1    20071129        BlackRock Series Fund, Inc.  \n",
      "2    20071129        BlackRock Series Fund, Inc.  \n",
      "3    20071129        BlackRock Series Fund, Inc.  \n",
      "4    20071129        BlackRock Series Fund, Inc.  \n",
      "5    20071129        BlackRock Series Fund, Inc.  \n",
      "..        ...                                ...  \n",
      "1    20140723  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "2    20140723  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "3    20140723  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "0    20150122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "1    20150122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "2    20150122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "0    20150723  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "1    20150723  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "2    20150723  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "0    20160122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "1    20160122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "2    20160122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "0    20160726  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "1    20160726  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "2    20160726  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "0    20170124  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "1    20170124  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "2    20170124  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "0    20170724  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "1    20170724  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "2    20170724  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "0    20180122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "1    20180122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "2    20180122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "0    20180723  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "1    20180723  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "2    20180723  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "0    20190122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "1    20190122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "2    20190122  BLACKROCK FOCUS GROWTH FUND, INC.  \n",
      "\n",
      "[370 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(panel2)\n",
    "panel2.to_csv(os.path.join(cur_wd, 'panel2.csv'), sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Cleaning on One File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_junk(addline):\n",
    "    addline = re.sub('<[^>]*>', ' ', addline)\n",
    "    addline = re.sub('&nbsp;', ' ', addline)\n",
    "    addline = re.sub('&#174;', ' ', addline)\n",
    "    addline = re.sub('&#8480;', ' ', addline)\n",
    "    addline = re.sub(r'&reg;',' ',addline)\n",
    "    addline = re.sub(r'\\n', ' ', addline)\n",
    "    addline = re.sub(r'\\t', ' ', addline)\n",
    "    return addline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_dict(i):\n",
    "    \n",
    "    cf = open(os.path.join(cur_wd, CIK, 'n-q',i), mode='r') \n",
    "\n",
    "    hold = False\n",
    "    add = False\n",
    "    split_qtly = {}\n",
    "\n",
    "    getNexyLine = False\n",
    "    \n",
    "    \n",
    "    reporting_date = 'not found'\n",
    "    \n",
    "    for j in cf:\n",
    "        j = j.lower()\n",
    "        cleaned_j = remove_junk(j)\n",
    "        \n",
    "\n",
    "            if remove_junk(j) != '' and ('blackrock' in j or 'fund' in j or 'index' in j or 'llc' in j):\n",
    "                fund_quarterly_name = remove_junk(j)\n",
    "                fund_quarterly_name = \" \".join(fund_quarterly_name.split())\n",
    "                print(fund_quarterly_name)\n",
    "                getNexyLine = False\n",
    "            \n",
    "                key = fund_quarterly_name\n",
    "                split_qtly[key] = {}\n",
    "                split_qtly[key]['holdings'] = []\n",
    "                split_qtly[key]['name'] = fund_quarterly_name\n",
    "\n",
    "                hold = True\n",
    "        \n",
    "        \n",
    "        if hold:\n",
    "            \n",
    "            if r'<tr' in j:\n",
    "                addstring = ''\n",
    "                add = True\n",
    "\n",
    "            try:\n",
    "                if r'</tr>' in j:\n",
    "                    addstring = \" \".join(addstring.split())\n",
    "                    add = False\n",
    "                    if addstring != '':\n",
    "                        if hold:\n",
    "                            split_qtly[key]['holdings'].append(addstring)\n",
    "                            \n",
    "                            \n",
    "                        if 'date of reporting period' in addstring:\n",
    "                            print(addstring)\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "                        \n",
    "\n",
    "            if add:\n",
    "                addline = remove_junk(j)\n",
    "                addstring = addstring + ' ' + addline\n",
    "    \n",
    "                        \n",
    "    return split_qtly, reporting_date\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/1097293/0001193125-19-013629.txt\n",
      "blackrock focus growth fund, inc.\n",
      "master focus growth llc\n",
      "master focus growth llc\n",
      "master focus growth llc\n",
      "reporting date\n",
      "  11/30/2018   \n"
     ]
    }
   ],
   "source": [
    "CIK  ='1097293'\n",
    "i = '0001193125-19-013629.txt'\n",
    "text = i\n",
    "fundNames = panel2.loc[panel2['file_read'] == text, 'SERIES-NAME'].unique()\n",
    "\n",
    "series_names = panel2.loc[panel2['file_read'] == text, 'SERIES-NAME'].unique().tolist()\n",
    "series_names = list(map(lambda x:x.lower(),series_names))\n",
    "\n",
    "if '.csv' not in i:\n",
    "    for z in weblink[CIK]:\n",
    "        if i in z:\n",
    "            matching_link = z\n",
    "    print(matching_link)\n",
    "    \n",
    "    split_qtly, reporting_date = get_info_dict(i)\n",
    "    key = list(split_qtly.keys())[0]\n",
    "    print('reporting date')\n",
    "    print(reporting_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean the legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings_dict = {}\n",
    "for j in split_qtly.keys():\n",
    "\n",
    "    split_qtly[j]['cleaned holdings'] = []\n",
    "    for i in split_qtly[j]['holdings']:\n",
    "\n",
    "        if hasNumbers(i) and i[-1] != r'%' and 'total investment' not in i and 'principalamount' not in i:\n",
    "            cleaned_i = remove_junk(i)\n",
    "            cleaned_i  = cleaned_i.replace(r'$', ' ')\n",
    "            cleaned_i  = cleaned_i.replace(r',', '')\n",
    "            cleaned_i = cleaned_i.lstrip()\n",
    "            cleaned_i = cleaned_i.rstrip()\n",
    "            cleaned_i = \" \".join(cleaned_i.split())\n",
    "            isplit = cleaned_i.split(' ')\n",
    "            if len(isplit) >= 3:\n",
    "                if hasNumbers(isplit[-1]) and hasNumbers(isplit[-2]):\n",
    "                    if 'warrant' in cleaned_i or 'loan' in cleaned_i or 'lending' in cleaned_i or 'tranche' in \\\n",
    "                    cleaned_i or 'cash central' in cleaned_i :\n",
    "                        if 'warrant' in cleaned_i:\n",
    "                            split_qtly[j]['cleaned holdings'].append([i, 'warrant', ''])\n",
    "                        elif 'loan' in cleaned_i:\n",
    "                            split_qtly[j]['cleaned holdings'].append([i, 'loan', ''])\n",
    "                        elif 'trance' in cleaned_i:\n",
    "                            split_qtly[j]['cleaned holdings'].append([i, 'pooled-security', ''])\n",
    "                        else:\n",
    "                            split_qtly[j]['cleaned holdings'].append([i, 'non-equity', ''])\n",
    "\n",
    "                    else:\n",
    "                        non_dig = re.findall(r'\\D+', isplit[-2])\n",
    "                        non_dig = \" \".join(non_dig)\n",
    "                        isplit[-3] = isplit[-3] +' ' + non_dig\n",
    "                        isplit[-2] = isplit[-2].replace(non_dig, '')\n",
    "                        name = ' '.join(isplit[0:-2])\n",
    "                        name = name.lstrip()\n",
    "                        name = name.rstrip()\n",
    "                        split_qtly[j]['cleaned holdings'].append([name , isplit[-2], isplit[-1]])\n",
    "\n",
    "    holdings_dict[j] = split_qtly[j]['cleaned holdings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machinery 1621762 &#151; &# ;', '&#151;', '1621762']\n"
     ]
    }
   ],
   "source": [
    "print(holdings_dict[j][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machinery 1621762 &#151; &# ;', '&#151;', '1621762']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdings_dict[j][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getPanel1_add(split_qtly, matching_link, text, cik):\n",
    "    \n",
    "    #get the security legend\n",
    "    \n",
    "    leg_dict = {}\n",
    "\n",
    "    for j in split_qtly.keys():\n",
    "        count = 0\n",
    "        split_qtly[j]['cleaned legend'] = []\n",
    "        leg_dict[j]= {}\n",
    "\n",
    "        restricted_securities = []\n",
    "        for i in split_qtly[j]['legend']:\n",
    "            i = i.rstrip().lstrip()\n",
    "            keys = re.search('\\(([^()]*)\\)',i)\n",
    "            try: \n",
    "                keys = keys.group()\n",
    "                if r'(' in i and r')' in i and len(keys) == 3:\n",
    "                    split_qtly[j]['cleaned legend'].append(i.rstrip().lstrip()) \n",
    "                    if i.rstrip().lstrip()[0:3] not in leg_dict[j].keys():\n",
    "                        leg_dict[j][i.rstrip().lstrip()[0:3]] = i.rstrip().lstrip()[3:]\n",
    "            except:\n",
    "                pass\n",
    "            count = count + 1\n",
    "\n",
    "    df_legend = pd.DataFrame()\n",
    "\n",
    "    for j in leg_dict.keys():\n",
    "        try:\n",
    "            add = pd.DataFrame.from_dict(leg_dict[j], orient = 'index')\n",
    "            add.columns = ['code']\n",
    "            add.loc[:, 'identifer'] = j\n",
    "            add.loc[:, 'weblink'] = matching_link\n",
    "            add.loc[:, 'textfile'] = text\n",
    "\n",
    "            if df_legend.empty:\n",
    "                df_legend = add.copy()\n",
    "            else:\n",
    "                df_legend = pd.concat([df_legend, add], axis = 0)\n",
    "        except ValueError:\n",
    "            #there is no legend\n",
    "            pass\n",
    "            \n",
    "            \n",
    "    #get the security acquisition data\n",
    "    \n",
    "    acq_dict = {}\n",
    "\n",
    "    for j in split_qtly.keys():\n",
    "        split_qtly[j]['cleaned acq'] = []\n",
    "        for i in split_qtly[j]['acq']:\n",
    "            if hasNumbers(i) and r'$' in str(i):\n",
    "                clean_i = str(i).replace(r'$', r' $')\n",
    "                if clean_i.count(r\"$\") == 1 and clean_i.count(r\"/\") >= 2:\n",
    "                    clean_i = clean_i.split(r' $')\n",
    "                    cost = clean_i[1].lstrip().rstrip()\n",
    "                    date = re.findall('\\d{1,2}/\\d{1,2}/\\d{2,4}', clean_i[0])\n",
    "                    date = \" - \".join(date)\n",
    "                    date = date.lstrip().rstrip()\n",
    "                    name = clean_i[0].replace(date, '')\n",
    "                    name = name.lstrip()\n",
    "                    name = name.rstrip()\n",
    "                    if name != 'equities':\n",
    "                        split_qtly[j]['cleaned acq'].append([name, date, cost])\n",
    "        acq_dict[j] = split_qtly[j]['cleaned acq']\n",
    "\n",
    "    df_acq = pd.DataFrame()\n",
    "    for j in acq_dict.keys():\n",
    "        if len(acq_dict[j]) > 0:\n",
    "            add = pd.DataFrame(acq_dict[j])\n",
    "            add.columns = ['acq name', 'acq date', 'acq cost']\n",
    "            add.loc[:, 'identifer'] = j\n",
    "            add.loc[:, 'weblink'] = matching_link\n",
    "            add.loc[:, 'textfile'] = text\n",
    "            add.loc[:, 'CIK'] = cik\n",
    "            add.loc[:, 'fund name'] = split_qtly[j]['name']\n",
    "\n",
    "            if df_acq.empty:\n",
    "                df_acq = add.copy()\n",
    "            else:\n",
    "                df_acq = pd.concat([df_acq, add], axis = 0)\n",
    "            \n",
    "    #get the holdings data\n",
    "    \n",
    "    holdings_dict = {}\n",
    "    value_mult = ''\n",
    "    for j in split_qtly.keys():\n",
    "        \n",
    "        leg_dict[j]\n",
    "        split_qtly[j]['cleaned holdings'] = []\n",
    "        for i in split_qtly[j]['holdings']:\n",
    "            \n",
    "            if r'value (' in i:\n",
    "                value_mult = remove_junk(i)\n",
    "                value_mult = str(re.findall('\\((.*?)\\)',value_mult)[0])\n",
    "\n",
    "            elif hasNumbers(i) and i[-1] != r'%' and 'total investment' not in i and 'principalamount' not in i \\\n",
    "            and r'cost)' not in i and r'(cost' not in i and 'net asset' not in i:\n",
    "                keys_found, cleaned_i = get_keys(leg_dict, j, i)\n",
    "                cleaned_i  = cleaned_i.replace(r'$', ' ')\n",
    "                cleaned_i  = cleaned_i.replace(r',', '')\n",
    "                cleaned_i = cleaned_i.lstrip()\n",
    "                cleaned_i = cleaned_i.rstrip()\n",
    "                cleaned_i = \" \".join(cleaned_i.split())\n",
    "                isplit = cleaned_i.split(' ')\n",
    "                if len(isplit) >= 3:\n",
    "                    if hasNumbers(isplit[-1]) and hasNumbers(isplit[-2]):\n",
    "                        if 'warrant' in cleaned_i or 'loan' in cleaned_i or 'lending' in cleaned_i or 'tranche' in \\\n",
    "                        cleaned_i or 'cash central' in cleaned_i or r'%' in cleaned_i:\n",
    "                            if 'warrant' in cleaned_i:\n",
    "                                split_qtly[j]['cleaned holdings'].append([i, 'warrant', '',keys_found, value_mult])\n",
    "                            elif 'loan' in cleaned_i and 'tranche' not in cleaned_i:\n",
    "                                split_qtly[j]['cleaned holdings'].append([i, 'loan', '',keys_found, value_mult])\n",
    "                            elif 'tranche' in cleaned_i:\n",
    "                                split_qtly[j]['cleaned holdings'].append([i, 'pooled-security', '',keys_found, value_mult])\n",
    "                            elif 'cash central' in cleaned_i:\n",
    "                                split_qtly[j]['cleaned holdings'].append([i, 'cash central fund', '',keys_found, value_mult])\n",
    "                            elif r'%' in cleaned_i and r'/' in cleaned_i:\n",
    "                                split_qtly[j]['cleaned holdings'].append([i, 'corporate bond', '',keys_found, value_mult])\n",
    "                            elif r'%' in cleaned_i and r'/' not in cleaned_i:\n",
    "                                split_qtly[j]['cleaned holdings'].append([i, 'pref stock', '',keys_found, value_mult])\n",
    "                            else:\n",
    "                                split_qtly[j]['cleaned holdings'].append([i, 'non-equity', '',keys_found, value_mult])\n",
    "                        else:\n",
    "                            non_dig = re.findall(r'\\D+', isplit[-2])\n",
    "                            non_dig = \" \".join(non_dig)\n",
    "                            isplit[-3] = isplit[-3] +' ' + non_dig\n",
    "                            isplit[-2] = isplit[-2].replace(non_dig, '')\n",
    "                            name = ' '.join(isplit[0:-2])\n",
    "                            name = name.lstrip()\n",
    "                            name = name.rstrip()\n",
    "                            split_qtly[j]['cleaned holdings'].append([name , isplit[-2], isplit[-1],keys_found, value_mult])\n",
    "            elif ':' in i:\n",
    "                if 'total investment' not in i and 'principalamount' not in i \\\n",
    "                and r'cost)' not in i and r'(cost' not in i and 'net asset' not in i:\n",
    "                    keys_found, cleaned_i = get_keys(leg_dict, j, i)\n",
    "                    cleaned_i  = cleaned_i.replace(r'$', ' ')\n",
    "                    cleaned_i  = cleaned_i.replace(r',', '')\n",
    "                    cleaned_i = cleaned_i.lstrip()\n",
    "                    cleaned_i = cleaned_i.rstrip()\n",
    "                    cleaned_i  = cleaned_i.replace(r':', '')\n",
    "                    cleaned_i = \" \".join(cleaned_i.split())\n",
    "                    split_qtly[j]['cleaned holdings'].append([i, 'header', '',keys_found, value_mult])\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        holdings_dict[j] = split_qtly[j]['cleaned holdings']\n",
    "\n",
    "    df_holdings = pd.DataFrame()\n",
    "    for j in holdings_dict.keys():\n",
    "        add = pd.DataFrame(holdings_dict[j])\n",
    "        add.columns = ['holdings name', 'holdings shares', 'holdings value', 'key', 'value multiplier']\n",
    "        add.loc[:, 'identifer'] = j\n",
    "        add.loc[:, 'weblink'] = matching_link\n",
    "        add.loc[:, 'textfile'] = text\n",
    "        add.loc[:, 'CIK'] = cik\n",
    "        add.loc[:, 'fund name'] = split_qtly[j]['name']\n",
    "\n",
    "        if df_holdings.empty:\n",
    "            df_holdings = add.copy()\n",
    "        else:\n",
    "            df_holdings = pd.concat([df_holdings, add], axis = 0)\n",
    "\n",
    "    df_holdings = df_holdings.drop_duplicates(subset = ['holdings name', 'holdings shares', 'holdings value'])\n",
    "    df_acq = df_acq.drop_duplicates(subset = ['acq name', 'acq date', 'acq cost'])\n",
    "    \n",
    "    \n",
    "    return df_legend, df_acq, df_holdings\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Panel 1 FOR ALL CIKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "panel1 = pd.DataFrame()\n",
    "panel1_legend = pd.DataFrame()\n",
    "error_panel1 = []\n",
    "\n",
    "for CIK in CIK_LIST:\n",
    "    txt_files = os.listdir(os.path.join(cur_wd, CIK, 'n-q'))\n",
    "    \n",
    "    for i in txt_files:\n",
    "        if '.csv' not in i and i not in error_panel2:\n",
    "            for z in weblink[CIK]:\n",
    "                if i in z:\n",
    "                    matching_link = z\n",
    "            print(matching_link)\n",
    "\n",
    "            split_qtly, reporting_date = get_info_dict(i)\n",
    "            try:\n",
    "                #get the panel1 data\n",
    "                df_legend, df_acq, df_holdings = getPanel1_add(split_qtly, matching_link, i, CIK)\n",
    "                \n",
    "                #combine the holdings and acq data in one panel\n",
    "                df_holdings = pd.concat([df_holdings, df_acq], axis = 0)\n",
    "                \n",
    "                #add the conformed data and date filed to panel 1 by reading the date_filed\n",
    "                date_filed = panel2.loc[panel2['file_read'] == i, 'date_filed'].unique()[0]\n",
    "                conformed_name = panel2.loc[panel2['file_read'] == i, 'company conformed name'].unique()[0]\n",
    "                \n",
    "                df_holdings.loc[:, 'date_filed'] = date_filed\n",
    "                df_holdings.loc[:, 'reporting_date'] = reporting_date\n",
    "                df_holdings.loc[:, 'company conformed name'] = conformed_name\n",
    "                \n",
    "                #add the new holdings data modified to panel 1 and also add legend information to output panels\n",
    "                if panel1.empty:\n",
    "                    panel1 = df_holdings.copy()\n",
    "                    panel1_legend = df_legend.copy()\n",
    "                else:\n",
    "                    panel1 = pd.concat([panel1, df_holdings] , axis = 0)\n",
    "                    panel1_legend = pd.concat([panel1_legend, df_legend], axis = 0)\n",
    "            except:\n",
    "                print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "                error_panel1.append(i)\n",
    "                print(CIK)\n",
    "                print(i)\n",
    "         \n",
    "print('errors')\n",
    "print(error_panel1)\n",
    "\n",
    "#panel1.to_csv(os.path.join(cur_wd, 'panel1.csv'), sep = ',')\n",
    "panel1_legend.to_csv(os.path.join(cur_wd, 'panel1_legend.csv'), sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map the header information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel1 = panel1.reset_index(drop=True)\n",
    "for index, row in panel1.iterrows():\n",
    "    if row['holdings shares'] == 'header':\n",
    "        lastheader = str(row['holdings name'].replace(r':', ''))\n",
    "    if not pd.isnull(row['holdings name']):\n",
    "        if str(row['holdings name'][0:len('class')]).lower() == 'class':\n",
    "            panel1.loc[panel1.index == index, 'holdings name'] = lastheader + r'_' + str(row['holdings name'])\n",
    "        elif str(row['holdings name'][0:len('series')]).lower() == 'series':\n",
    "            panel1.loc[panel1.index == index, 'holdings name'] = lastheader + r'_' + str(row['holdings name'])\n",
    "        elif str(row['holdings name'][0:len('warrants')]).lower() == 'warrants':\n",
    "            panel1.loc[panel1.index == index, 'holdings name'] = lastheader + r'_' + str(row['holdings name'])\n",
    "        elif str(row['holdings name'][0:len('adr')]).lower() == 'adr':\n",
    "            panel1.loc[panel1.index == index, 'holdings name'] = lastheader + r'_' + str(row['holdings name'])            \n",
    "        elif r'%' in row['holdings name'] and  hasNumbers(row['holdings name'][0]):\n",
    "            panel1.loc[panel1.index == index, 'holdings name'] = lastheader + r'_' + str(row['holdings name'])\n",
    "\n",
    "panel1 = panel1.loc[panel1['holdings shares'] != 'header']     \n",
    "panel1.to_csv(os.path.join(cur_wd, 'panel1.csv'), sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the restricted securities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel1_legend.loc[:,'restricted'] = 'no'\n",
    "\n",
    "acq = panel1.loc[~panel1['acq date'].isnull()]\n",
    "\n",
    "panel1_legend.loc[panel1_legend['code'].str.contains(\"restrict\") | panel1_legend['code'].str.contains(\"level 3 security\") \\\n",
    "              | panel1_legend['code'].str.contains(\"exempt from registration\"), 'restricted'] = 'yes'\n",
    "\n",
    "restricted = panel1_legend.loc[panel1_legend['restricted'].str.contains(\"yes\")]\n",
    "restricted.to_csv(os.path.join(cur_wd, 'restricted_legend.csv'), sep = ',')\n",
    "\n",
    "panel1.loc[:,'restricted'] = 'no'\n",
    "\n",
    "for index, row in restricted.iterrows():\n",
    "    panel1.loc[(panel1['identifer'] == row['identifer']) & (panel1['textfile'] == row.textfile) \\\n",
    "                   & (panel1['key'].str.contains(index)), 'restricted'] = 'yes'\n",
    "\n",
    "#add the acquisition data\n",
    "\n",
    "print(len(panel1))\n",
    "restricted_panel1 = panel1.loc[(panel1['restricted'] == 'yes')]\n",
    "print(len(restricted_panel1))\n",
    "restricted_panel1 = pd.concat([panel1.loc[(panel1['restricted'] == 'yes')], acq], axis = 0)\n",
    "print(len(restricted_panel1))\n",
    "restricted_panel1.to_csv(os.path.join(cur_wd, 'panel1_restricted.csv'), sep = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
